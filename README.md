# Neural-Network
In this project I show how, we can create a neural network from scratch and how I am using the Gradient descent to optimize the weights 

    APPROXIMATING A POLYNOMIAL FUNCTION
In this I have defined a random polynomial function and assign it some weight and we let the neural netwrok learn the weights by optimizing the weights using gradient descent approach.

    APPROXIMATING THE SUM OF TW0 NUMBERS
In this I have defined the neural network with no hidden layer as of now with just biasness, to approximate the sum of two numbers where the bias term is always 1 and the weights have to 0, for biasterm in order to approximate the sum function.

    APPROXIMATION OF SIGN OF THE GIVEN SUM FOR TWO NUMBERS
In this I have added a hidden layer and it is giving out two outputs neurons as [1,0] for negative sum of two numbers and [1,0] for positive sum of two numbers, I have removed the examples where the sum was 0 by adding 0.1 and making them positive numbers for this example. In this I have also used the sigmoid activation function whoch will scale the values to [0.1].

    APPROXIMATING THE IMAGE DATA USING MNIST DATASET
In this I am trying to predict the number using the images data and given labels of the data and I am defining 2 hidden layers in between and I am using matrixes for multiplication as they are faster. We have 10 output vectors basically that correspond to each didgit in the dataset that ranges from 0 to 9.
And I have 10 hidden layers as well.


    
